{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40d2c47-2489-4cff-a14e-fc90cc63e75d",
   "metadata": {
    "name": "Title",
    "collapsed": false,
    "resultHeight": 112
   },
   "source": "# Tasty Bytes - RAG Chatbot Using Cortex and Streamlit"
  },
  {
   "cell_type": "code",
   "id": "8302b3d2-222c-4cba-8633-737a351b7532",
   "metadata": {
    "language": "sql",
    "name": "verify_env",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "-- verify current environment\nSELECT \n    CURRENT_WAREHOUSE(),\n    CURRENT_DATABASE(),\n    CURRENT_SCHEMA(),\n    CURRENT_ROLE();",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ddfbb07f-c9ab-4373-9dc0-6df3a0ce7d48",
   "metadata": {
    "name": "Step_1_db_setup",
    "collapsed": false,
    "resultHeight": 609
   },
   "source": "## Step 1 : TastyBytes Chatbot Database Setup\n\n### Overview\nThis section establishes the core database infrastructure for the TastyBytes chatbot application. The setup includes:\n- Main application database\n- Dedicated application schema\n- Compute warehouse configuration\n\n### Architecture Components\n1. **Database Layer** - tasty_bytes_chatbot database serves as the main container\n2. **Schema Layer** - app schema organizes related objects\n3. **Compute Layer** - Large warehouse handles processing needs\n\n### Technical Implementation\nThe setup uses Snowflake's CREATE OR REPLACE syntax for idempotent deployment:\n- Database creation establishes the top-level container\n- Schema creation provides logical organization\n- Warehouse configuration optimizes for performance and cost"
  },
  {
   "cell_type": "code",
   "id": "ade27256-4842-41d2-922e-597f4c7fe035",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "-- Database\nCREATE OR REPLACE DATABASE tasty_bytes_chatbot;\n\n--Schema\nCREATE OR REPLACE SCHEMA tasty_bytes_chatbot.app;\n\n--Warehouse\nCREATE OR REPLACE WAREHOUSE tasty_bytes_chatbot_wh with\nWAREHOUSE_SIZE = LARGE\nAUTO_SUSPEND = 60;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "12fd7204-ae55-4a8d-9467-10099b1b3f25",
   "metadata": {
    "name": "Step_2_data_load",
    "collapsed": false,
    "resultHeight": 526
   },
   "source": "## Step 2: Data Loading Infrastructure Setup\n\n### Overview\nThis section configures essential components for loading data into the TastyBytes chatbot system:\n- CSV file format specification\n- External stage connection to S3 bucket\n\n### Components\n1. **File Format** - Defines CSV parsing rules\n2. **External Stage** - Creates secure connection to S3 source data\n\n### Technical Details\nThe setup enables automated data ingestion from the TastyBytes quickstart S3 bucket:\n- File format supports CSV data processing\n- S3 stage connects to pre-populated sample data\n- Components are created in the app schema for organized access"
  },
  {
   "cell_type": "code",
   "id": "1f16d385-3615-47ab-89f8-1f0b66a501fa",
   "metadata": {
    "language": "sql",
    "name": "cell12",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "-- Create file format for CSV processing\nCREATE OR REPLACE FILE FORMAT tasty_bytes_chatbot.app.csv_ff \nTYPE = 'csv';\n\n-- Create external stage to connect to S3 data source\nCREATE OR REPLACE STAGE tasty_bytes_chatbot.app.s3load\nCOMMENT = 'Quickstarts S3 Stage Connection'\nurl = 's3://sfquickstarts/tastybytes-cx/app/'\nfile_format = tasty_bytes_chatbot.app.csv_ff;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2225a2f7-ebdc-41fe-acca-49aa557eeeda",
   "metadata": {
    "name": "Step_3_doc_storage",
    "collapsed": false,
    "resultHeight": 564
   },
   "source": "## Step 3 : Document Storage Setup\n\n### Overview\nThis section establishes the document storage infrastructure for the TastyBytes chatbot:\n- Creates a table for storing document metadata and content\n- Loads initial document data from S3 stage\n\n### Table Structure\nThe documents table contains:\n- RELATIVE_PATH: Document location identifier\n- RAW_TEXT: Actual document content\nBoth fields use VARCHAR with maximum capacity for flexibility\n\n### Implementation Notes\nThe setup includes:\n- Table creation with JSON metadata for tracking\n- Bulk data load from staged S3 files\n- Integration with previously configured external stage"
  },
  {
   "cell_type": "code",
   "id": "8b862062-5ad5-4259-9424-af955327d3e5",
   "metadata": {
    "language": "sql",
    "name": "cell14",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "-- Create table for storing document content and metadata\nCREATE OR REPLACE TABLE tasty_bytes_chatbot.app.documents (\n\tRELATIVE_PATH VARCHAR(16777216),\n\tRAW_TEXT VARCHAR(16777216)\n)\nCOMMENT = '{\"origin\":\"sf_sit-is\", \"name\":\"voc\", \"version\":{\"major\":1, \"minor\":0}, \"attributes\":{\"is_quickstart\":1, \"source\":\"streamlit\", \"vignette\":\"rag_chatbot\"}}';\n\n-- Load initial document data from S3 stage\nCOPY INTO tasty_bytes_chatbot.app.documents\nFROM @tasty_bytes_chatbot.app.s3load/documents/;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ca36e9aa-c2e5-44b3-ac3a-10d422dfb365",
   "metadata": {
    "name": "Step_4_vector_store",
    "collapsed": false,
    "resultHeight": 670
   },
   "source": "## Step 4 : Vector Store Implementation\n\n### Overview\nThis section implements the vector storage system for embeddings:\n- Creates temporary array-based staging table\n- Creates final vector store with proper VECTOR data type\n- Transforms array data into optimized vector format\n\n### Architecture\nThe implementation follows a two-step process:\n1. **Staging Layer** - array_table stores raw array data\n2. **Production Layer** - vector_store contains optimized VECTOR columns\n\n### Technical Details\n- Uses ARRAY type for initial data loading (Snowflake requirement)\n- Converts to VECTOR(FLOAT, 768) for optimized storage and querying\n- Maintains source tracking and text content alongside embeddings\n- VECTOR type cannot be loaded directly, requiring ARRAY intermediate storage\n- 768-dimension vectors match standard NLP embedding models\n- VARCHAR fields use maximum length for flexibility\n- Source tracking enables multi-source embedding management\n\n"
  },
  {
   "cell_type": "code",
   "id": "b8ac392b-b69d-4de6-9f6d-ba498ce16356",
   "metadata": {
    "language": "sql",
    "name": "cell16",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "-- https://docs.snowflake.com/en/sql-reference/data-types-vector#loading-and-unloading-vector-data\n-- Create staging table with ARRAY type for initial data load\nCREATE OR REPLACE TABLE tasty_bytes_chatbot.app.array_table (\n  SOURCE VARCHAR(6),\n\tSOURCE_DESC VARCHAR(16777216),\n\tFULL_TEXT VARCHAR(16777216),\n\tSIZE NUMBER(18,0),\n\tCHUNK VARCHAR(16777216),\n\tINPUT_TEXT VARCHAR(16777216),\n\tCHUNK_EMBEDDING ARRAY\n);\n\n-- Load vector data from S3 into staging table\nCOPY INTO tasty_bytes_chatbot.app.array_table\nFROM @tasty_bytes_chatbot.app.s3load/vector_store/;\n\n-- Create optimized vector store with proper VECTOR type\nCREATE OR REPLACE TABLE tasty_bytes_chatbot.app.vector_store (\n\tSOURCE VARCHAR(6),\n\tSOURCE_DESC VARCHAR(16777216),\n\tFULL_TEXT VARCHAR(16777216),\n\tSIZE NUMBER(18,0),\n\tCHUNK VARCHAR(16777216),\n\tINPUT_TEXT VARCHAR(16777216),\n\tCHUNK_EMBEDDING VECTOR(FLOAT, 768)\n) AS\nSELECT \n  source,\n\tsource_desc,\n\tfull_text,\n\tsize,\n\tchunk,\n\tinput_text,\n  chunk_embedding::VECTOR(FLOAT, 768)\nFROM tasty_bytes_chatbot.app.array_table;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa239156-ccb9-4c93-9498-83d95b204d32",
   "metadata": {
    "name": "Step_5_streamlit_app",
    "collapsed": false,
    "resultHeight": 1758
   },
   "source": "##  Step 5 : Create Streamlit App\n\n## TastyBytes Support Chatbot Implementation\n\n### Overview\nThis Streamlit application implements a RAG-based customer support chatbot that:\n- Uses Cortex LLMs for generating responses\n- Leverages vector similarity search for relevant context\n- Maintains chat history for contextual responses\n- Allows model selection flexibility\n\n### Architecture Components\n1. **Core Dependencies**\n   - Snowpark for data access\n   - Cortex for LLM operations\n   - Streamlit for UI/UX\n   - Pandas for data manipulation\n\n2. **Key Features**\n   - Model selection from multiple LLM options\n   - Vector similarity-based document retrieval\n   - Context-aware response generation\n   - Chat history management\n\n### Implementation Notes\n- Uses VECTOR_COSINE_SIMILARITY for document matching\n- Maintains 20-message chat history\n- Sanitizes inputs for SQL safety\n- Provides real-time status updates\n\n### Configuration Steps\n1. **Access Streamlit**\n   - Open Snowsight interface\n   - Navigate to \"Projects\" menu\n   - Select \"Streamlit\" tab\n\n2. **Create New Application**\n   - Click \"+ Streamlit App\" button\n   - Enter application name\n   - Configure required resources:\n     * Database: TASTY_BYTES_CHATBOT\n     * Schema: APP\n     * Warehouse: TASTY_BYTES_CHATBOT_WH\n\n3. **Setup Dependencies**\n   - Open code editor section\n   - Access \"Packages\" dropdown menu\n   - Add snowpark-ml-python package\n   - This enables ML capabilities for the chatbot\n\n4. **Deploy Application**\n   - Copy implementation code to editor\n   - Click \"Run\" to deploy application\n   - Monitor deployment status\n\n### Technical Requirements\n- Active Snowflake account with appropriate privileges\n- Access to specified database and schema\n- Configured warehouse with adequate resources\n- Required Python packages available"
  },
  {
   "cell_type": "markdown",
   "id": "16c36f36-2e78-4c88-8088-bfb9050bf647",
   "metadata": {
    "name": "cleanup",
    "collapsed": false,
    "resultHeight": 74
   },
   "source": "# Cleanup"
  },
  {
   "cell_type": "code",
   "id": "ff004413-6a59-4280-9ef2-f8ca2b941587",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "-- Drop tables\nDROP TABLE IF EXISTS tasty_bytes_chatbot.app.vector_store;\nDROP TABLE IF EXISTS tasty_bytes_chatbot.app.array_table;\nDROP TABLE IF EXISTS tasty_bytes_chatbot.app.documents;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e28788b8-841e-4af8-93ac-ae6077c1ce8d",
   "metadata": {
    "language": "sql",
    "name": "cell10",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "use warehouse compute_wh;\nuse database notebooks_db;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f45f2765-57f5-45fb-8dce-724b788c8060",
   "metadata": {
    "language": "sql",
    "name": "cell9",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "SELECT \n    CURRENT_WAREHOUSE(),\n    CURRENT_DATABASE(),\n    CURRENT_SCHEMA(),\n    CURRENT_ROLE();",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "26b45685-ad36-44e1-b12f-36840da69a28",
   "metadata": {
    "language": "sql",
    "name": "cell8",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "\n\n-- Drop stage\nDROP STAGE IF EXISTS tasty_bytes_chatbot.app.s3load;\n\n-- Drop file format\nDROP FILE FORMAT IF EXISTS tasty_bytes_chatbot.app.csv_ff;\n\n-- Drop schema\nDROP SCHEMA IF EXISTS tasty_bytes_chatbot.app;\n\n-- Drop warehouse\nDROP WAREHOUSE IF EXISTS tasty_bytes_chatbot_wh;\n\n-- Drop database\nDROP DATABASE IF EXISTS tasty_bytes_chatbot;",
   "execution_count": null
  }
 ]
}